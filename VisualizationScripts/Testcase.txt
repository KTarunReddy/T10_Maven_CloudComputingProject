//import sys.process._

// sc is an existing SparkContext.
val sqlContext = new org.apache.spark.sql.SQLContext(sc)




val bankText = sc.textFile("bank-full.csv")



case class Bank(age: Integer, job: String, marital: String, education: String, balance: Integer)



val bank = bankText.map(s => s.split(";")).filter(s => s(0) != "\"age\"").map(

	s => Bank(s(0).toInt, 
		s(1).replaceAll("\"", ""),

		s(2).replaceAll("\"", ""),

		s(3).replaceAll("\"", ""),
		s(5).replaceAll("\"", "").toInt
        
	)

)
// toDF() works only in spark 1.3.0.

// For spark 1.1.x and spark 1.2.x,

// use below instead:

// bank.registerTempTable("bank"

bank.toDF().registerTempTable("bank")